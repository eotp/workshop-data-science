{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# The Python ecosystem - The statsmodels library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[statsmodels](http://www.statsmodels.org/dev/index.html#) is a Python module that provides classes and functions for the estimation of many different **statistical models**, as well as for conducting **statistical tests**, and **statistical data exploration**.\n",
    "\n",
    "\n",
    "* Regression Analysis\n",
    "* Linear Mixed Effects Models\n",
    "* ANOVA\n",
    "* Time Series analysis\n",
    "* Parametric and Nonparametric Statistical Methods\n",
    "* Multivariate Statistics multivariate\n",
    "* Distributions\n",
    "* and many more...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Add the `src` directory as one where we can import modules**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# add the 'src' directory as one where we can import modules\n",
    "src_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir, 'src'))\n",
    "sys.path.append(src_dir)\n",
    "print(src_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_funcs as hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population and Sample Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Inferential statistics](https://en.wikipedia.org/wiki/Statistical_inference) is all about using **sample results** to make decisions or predictions about a **population**. Basically, a numerical value is assigned to a population parameter based on the information collected from a sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the data set**\n",
    "\n",
    "Source [Crowder, M. and Hand, D. (1990)](https://stat.ethz.ch/R-manual/R-devel/library/datasets/html/ChickWeight.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken, chick_diet1, chick_diet2, chick_diet3, chick_diet4 = hf.load_chicken()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken[\"weight\"].plot.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Point Estimate and Confidence Interval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sample, the value of the computed sample statistic gives a point estimate of the corresponding population parameter. For example, the sample mean $(\\bar x)$, is a point estimate of the corresponding population mean, $\\mu$, or the sample standard deviation $s$ is a point estimate for the population standard deviation $\\sigma$. \n",
    "\n",
    "* [__sampling error__](https://en.wikipedia.org/wiki/Sampling_error) (the point estimate almost always differs from the true value of the population)\n",
    "\n",
    "\n",
    "### Interval Estimate \n",
    "\n",
    "Instead of assigning a single value to a population parameter, an interval estimation gives a probabilistic statement, relating the given interval to the probability that this interval actually contains the true (unknown) population parameter.\n",
    "\n",
    "\n",
    "The level of confidence is chosen a priori and thus depends on the users preferences. It is denoted by\n",
    "\n",
    "$$100(1-\\alpha)$$\n",
    "\n",
    "Although any value of confidence level can be chosen, the most common values are 90%, 95%, and 99%. When expressed as probability, the confidence level is called the confidence coefficient and is denoted by (1−$\\alpha$). Most common confidence coefficients are 0.90, 0.95, and 0.99, respectively.\n",
    "\n",
    "A 100(1−$\\alpha$)% confidence interval is an interval estimate around a population parameter $\\theta$ (here, the Greek letter $\\theta$ is a placeholder for any population parameter of interest such as the mean $\\mu$, or the standard deviation $\\sigma$, among others) that, under repeated random samples of size $N$, is expected to include $\\theta$'s true value 100(1−$\\alpha$)%  of the time ([Lovric 2010](http://www.springer.com/de/book/9783642048975)).\n",
    "\n",
    "The actual number added to and subtracted from the point estimate is called the margin of error.\n",
    "\n",
    "$$CI:\\text{Point estimate} \\pm \\text{Margin of error (ME)}$$\n",
    "\n",
    "\n",
    "Thus, the margin of error (ME) is expressed as\n",
    "\n",
    "\n",
    "$$ME = z^*_{\\alpha/2} \\times \\frac{\\sigma}{\\sqrt{n}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import DescrStatsW\n",
    "d_stats = DescrStatsW(chicken[\"weight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_mean = d_stats.mean\n",
    "d_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "d_conf_int = d_stats.tconfint_mean(alpha=alpha) \n",
    "print(d_conf_int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_level = int((1-alpha)*100)\n",
    "lower_ci = np.round(d_conf_int[0],1)\n",
    "upper_ci = np.round(d_conf_int[1],1)\n",
    "\n",
    "(print(\"We are {}% confident that the true weight of chicken is between {} and {} grams.\".\n",
    "       format(sig_level, lower_ci, upper_ci)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chicken.groupby(\"Diet\")[\"weight\"].mean() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ci(df, group, var, alpha=0.05):\n",
    "    groups = df[group].unique()\n",
    "    rv = pd.DataFrame({\"group\":None, \n",
    "                       \"mean\":None,\n",
    "                       \"lower_ci\":None,\n",
    "                       \"upper_ci\":None}, \n",
    "                      index=range(len(groups)))\n",
    "    for e, g in enumerate(groups):        \n",
    "        stats = DescrStatsW(df.loc[df[group] == g, var])\n",
    "        group_mean = stats.mean\n",
    "        group_ci = stats.tconfint_mean(alpha=alpha) \n",
    "        rv.loc[e] = {\"group\":g, \n",
    "                     \"mean\":group_mean,\n",
    "                     \"lower_ci\":group_ci[0],\n",
    "                     \"upper_ci\":group_ci[1]}\n",
    "    return rv\n",
    "        \n",
    "group_stats = compute_ci(df=chicken, group=\"Diet\", var=\"weight\")    \n",
    "group_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = group_stats[\"group\"].values\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(group_stats[\"mean\"].values, groups, \"o\")\n",
    "ax.set_ylim(0.5,4.5)\n",
    "\n",
    "for e,i in enumerate(group_stats[\"group\"]):\n",
    "    mean = group_stats[\"mean\"].values[e]\n",
    "    upper = group_stats[\"upper_ci\"].values[e]\n",
    "    lower = group_stats[\"lower_ci\"].values[e]\n",
    "    ax.plot((upper, lower),\n",
    "            (i,i), \"k--\")\n",
    "    ax.text(mean,i+0.1, \"Diet \"+str(int(i)), horizontalalignment='center')\n",
    "ax.legend([\"mean\", \"ci interval\"]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A very common problem that scientists face is the assessment of significance in scattered statistical data. Owing to the limited availability of observational data, scientists apply **inferential statistical methods to decide if the observed data contains significant information or if the scattered data is nothing more than the manifestation of the inherently probabilistic nature of the data generation process**.\n",
    "\n",
    "The framework of hypothesis testing is all about making statistical inferences about populations based on samples taken from the population. Any hypothesis test involves the **collection of data (sampling)**. If the **hypothesis** is assumed to be correct, the scientist can calculate the **expected results** of an experiment. If the **observed data** differs significantly from the expected results, then one considers the assumption to be incorrect. Thus, based on the observed data the scientist makes a **decision** as to whether or not there is sufficient evidence, based upon analyses of the data, that the model - the hypothesis - should be rejected, or that there is not sufficient evidence to reject the stated hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for differences in the mean (t-test)\n",
    "\n",
    "* variables normally distributed and independent\n",
    "* variance equal or not\n",
    "\n",
    "Null hypothesis\n",
    "$H_0:\\quad \\mu_1 = \\mu_2$\n",
    "\n",
    "Alternative hypothesis\n",
    "$H_A:\\quad \\mu_1 \\ne \\mu_2$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.weightstats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t, p, degf = ttest_ind(chick_diet2, chick_diet3)\n",
    "p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple comparisons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The problem with multiple comparisons is that the more hypotheses are tested on a particular data set, the more likely it is to incorrectly reject the null hypothesis. Thus, methods of multiple comparison require a higher significance threshold ($\\alpha$) for individual comparisons, in order to compensate for the number of inferences being made.\n",
    "\n",
    "\n",
    "**The Family-wise error rate**\n",
    "\n",
    "The family-wise error rate is the probability of making one or more false discoveries, or [__Type I errors__]() when performing multiple hypotheses tests.\n",
    "\n",
    "Recall that at a significance level of $\\alpha=0.05$, the probability of making a Type I error is equal to $0.05$ or $5\\%$. Consequently, the probability of not making a Type I error is $1-\\alpha=1-0.05=0.95$.\n",
    "\n",
    "\n",
    "Written more formally, for a family of $C$ tests, the probability of making a Type I error for the whole family is\n",
    "\n",
    "$$(1-\\alpha)^C\\text{.}$$\n",
    "\n",
    "Let us now consider $C=4$ and $\\alpha=0.05$.\n",
    "\n",
    "Thus, if we make 4 multiple comparisons on one data set, the probability of not making one or more Type I errors on the family of tests is $(1-\\alpha)^C = (1−0.05)^4 = 0.81$\n",
    "\n",
    "\n",
    "Null hypothesis\n",
    "$H_0:\\quad \\mu_1 = \\mu_2 = \\mu_3 = \\mu_4$\n",
    "\n",
    "Alternative hypothesis\n",
    "$H_A:\\quad \\mu_1 \\ne \\mu_2 \\ne \\mu_3 \\ne \\mu_4$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Tukey's HSD (Honestly Significant Difference)](https://en.wikipedia.org/wiki/Tukey%27s_range_test)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import MultiComparison\n",
    "mult_comp = MultiComparison(data=chicken[\"weight\"], groups=chicken[\"Diet\"])\n",
    "mult_comp.tukeyhsd(alpha=0.05).summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = mult_comp.tukeyhsd(alpha=0.05).plot_simultaneous()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "livereveal": {
   "scroll": true,
   "start_slideshow_at": "selected"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
